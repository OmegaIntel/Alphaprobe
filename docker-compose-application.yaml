services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - ./logs:/app/logs
      - ollama_data:/root/.ollama 
    environment:
      - PYTHONUNBUFFERED=1
      - OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME}
      - LLM_PROVIDER=ollama
      - LOCAL_LLM=deepseek-r1:8b
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DATABASE_HOST=${DATABASE_HOST}
      - DATABASE_USER_NAME=${DATABASE_USER_NAME}
      - DATABASE_PASSWORD=${DATABASE_PASSWORD}
      - DATABASE_NAME=${DATABASE_NAME}
      - DATABASE_PORT=${DATABASE_PORT}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - OLLAMA_BASE_URL=http://ollama:11434/
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_HOST=ollama
      - OLLAMA_PORT=11434

      - MAX_WEB_RESEARCH_LOOPS=3
      - FETCH_FULL_PAGE=false
      - SEARCH_API=duckduckgo
    depends_on:
      - ollama
  frontend:
    build:
      context: ./client
      dockerfile: Dockerfile
    ports:
      - "5173:5173"
    volumes:
      - ./client:/app
      - /app/node_modules
    environment:
      - VITE_API_BASE_URL=${VITE_API_BASE_URL}
    command: ["npm", "run", "dev"]


  ollama:                           
      image: ollama/ollama:latest
      container_name: ollama
      entrypoint: ["sh", "-c", "ollama pull deepseek-r1:8b && ollama serve --host 0.0.0.0:11434"]
      environment:
      # bind Ollama to all interfaces so other containers can reach it
        - OLLAMA_HOST=0.0.0.0:11434
      # allow cross-origin from anywhere (optional, but useful for embedding)
        - OLLAMA_ORIGINS=*
      volumes:
        - ollama_data:/root/.ollama
      ports:
        - "11434:11434"
      restart: unless-stopped

volumes:
  ollama_data: