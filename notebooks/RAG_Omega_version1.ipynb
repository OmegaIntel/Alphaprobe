{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wTxbciOYVo7V"
      },
      "outputs": [],
      "source": [
        "# %pip install llama-index llama-index-core llama-parse openai llama_index.embeddings.huggingface -q\n",
        "# %pip install llama-index-llms-anthropic -q\n",
        "# %pip install llama-index-vector-stores-weaviate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "COMPARISON_FILE = 'claude-3-5-sonnet-20240620_qa.csv'\n",
        "PDF_LOCATION = 'IndustrySource/Misc/62 Healthcare and Social Assistance in the US Industry Report.pdf'\n",
        "# PDF_PARSER = 'llm-sherpa'\n",
        "PDF_PARSER = 'llama-parse'\n",
        "DOC_ID = 'ibis-healthcare-social-assistance'\n",
        "MODEL_ID = 'gpt-4o-mini'\n",
        "OUTPUT_FILE = f'{DOC_ID}_{PDF_PARSER}_{MODEL_ID}.csv'\n",
        "QUESTION_COL = 'question'\n",
        "RESPONSE_COL = 'rag_model_response'\n",
        "NUM_QUESTIONS = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(COMPARISON_FILE)\n",
        "dff = df.head(NUM_QUESTIONS).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6gUzpLaeVpl5"
      },
      "outputs": [],
      "source": [
        "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# API access to llama-cloud\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-7K1IbMcLbyb8TDvMsIx3Brr7mD4K8ZnLaFMjbEq8S1uONYZp\"\n",
        "# Using OpenAI API for embeddings/llms\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_APIKEY')\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "from typing import List\n",
        "from llama_index.core.schema import Document\n",
        "\n",
        "def llama_parse_docs() -> List[Document]:\n",
        "    from llama_parse import LlamaParse\n",
        "    return LlamaParse(\n",
        "        result_type=\"markdown\",\n",
        "        gpt4o_api_key=OPENAI_API_KEY,\n",
        "        # fast_mode=True\n",
        "    ).load_data(PDF_LOCATION)\n",
        "\n",
        "def llmsherpa_docs() -> List[Document]:\n",
        "    from llmsherpa.readers import LayoutPDFReader\n",
        "    llmsherpa_api_url = \"http://localhost:5501/api/parseDocument?renderFormat=all\"\n",
        "    pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
        "    doc = pdf_reader.read_pdf(PDF_LOCATION)\n",
        "    chunks = doc.chunks()\n",
        "    min_page = min([chunk.page_idx for chunk in chunks])\n",
        "    max_page = max([chunk.page_idx for chunk in chunks])\n",
        "    pages = []\n",
        "    for page_idx in range(min_page, max_page+1):\n",
        "        cpage = [chunk.to_text() for chunk in chunks if chunk.page_idx == page_idx]\n",
        "        if cpage:\n",
        "            pages.append(Document(text='\\n'.join(cpage)))\n",
        "    return pages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjWQnAYnVwhF",
        "outputId": "9907e56f-9e80-404e-b2d2-36f3ab269b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started parsing the file under job_id b738e3ef-c865-4a3d-a382-970528ad1d88\n"
          ]
        }
      ],
      "source": [
        "if PDF_PARSER == 'llm-sherpa':\n",
        "    documents = llmsherpa_docs()\n",
        "else:\n",
        "    documents = llama_parse_docs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# IBISWorld | Healthcare and Social Assistance in the US\n",
            "\n",
            "# Mar 2024\n",
            "\n",
            "willingness to participate.\n",
            "\n",
            "- Many healthcare and social assistance entities will adopt digital and telehealth tools to bridge the gap between urban and rural communities regarding healthcare access. Grants awarded by the Biden Administration will help rural healthcare organizations expand critical services through digital tools.\n",
            "- Tech advances to address the widening needs of people of advanced age, like home health tools and remote monitoring equipment, will also become paramount. Instantaneous access to medical data through cloud infrastructure will also have a massive role in providing care for this population subset as medical needs mount.\n",
            "\n",
            "# Financial pressures will accelerate consolidation activity\n",
            "\n",
            "- The consolidation activity that defines the health sector will continue despite an economic environment of higher interest rates.\n",
            "- Mounting healthcare costs and reimbursement cuts will incentivize smaller, independent healthcare providers to join larger health groups. Larger health systems gain negotiating power with insurance providers to secure better rates.\n",
            "- Private equity (PE) investment will also be present in healthcare. Significant growth opportunities, in areas ranging from physical therapy and mental health to nursing and residential care, attract PE investment.\n"
          ]
        }
      ],
      "source": [
        "print(documents[25].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "# generate unique index for multiple runs\n",
        "INDEX_NAME = ('X' + str(uuid.uuid4())).replace('-', '_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NfaNIvokpbKo"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "\n",
        "cluster_url = \"https://a0dlgmcaspopjrn2mtx4ha.c0.us-east1.gcp.weaviate.cloud\"\n",
        "api_key = \"7ZfUCibywHnzM0WKMPx7YevuN79nUtS4KJgT\"\n",
        "\n",
        "client = weaviate.connect_to_wcs(\n",
        "    cluster_url=cluster_url,\n",
        "    auth_credentials=weaviate.auth.AuthApiKey(api_key),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbN-rN7lsEy0"
      },
      "source": [
        "# weaviate vector database & llamaparse Integrated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KtRzVlgesBiO"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hVThHH30qRoS"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
        "\n",
        "vector_store = WeaviateVectorStore(\n",
        "    weaviate_client=client, index_name=INDEX_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "esw4x1faqmmS"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "vector_index = VectorStoreIndex(nodes, vector_store = vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LMoIlj0qq-Wn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yakov/anaconda3/envs/probe/lib/python3.11/site-packages/pydantic/main.py:1059: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=MODEL_ID, api_key = OPENAI_API_KEY)\n",
        "query_engine = vector_index.as_query_engine(similarity_top_k=3, llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = []\n",
        "for question in dff[QUESTION_COL]:\n",
        "    result.append(query_engine.query(question))\n",
        "\n",
        "dff[RESPONSE_COL] = result\n",
        "dff.to_csv(OUTPUT_FILE, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
