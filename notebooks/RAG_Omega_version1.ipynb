{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wTxbciOYVo7V"
      },
      "outputs": [],
      "source": [
        "# %pip install llama-index llama-index-core llama-parse openai llama_index.embeddings.huggingface -q\n",
        "# %pip install llama-index-llms-anthropic -q\n",
        "# %pip install llama-index-vector-stores-weaviate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_braintrust_dataset = True\n",
        "\n",
        "COMPARISON_FILE = 'claude-3-5-sonnet-20240620_qa.csv'\n",
        "PDF_LOCATION = 'IndustrySource/Misc/62 Healthcare and Social Assistance in the US Industry Report.pdf'\n",
        "DOC_ID = 'ibis-healthcare-social-assistance'\n",
        "MODEL_ID = 'gpt-4o-mini'\n",
        "QUESTION_COL = 'question'\n",
        "RESPONSE_COL = 'rag_model_response'\n",
        "NUM_QUESTIONS = -1\n",
        "PARSER = \"llama-parse\"\n",
        "CHUNK_SIZE = 400\n",
        "SPLITTER = \"sentence\"\n",
        "TOP_K = 3\n",
        "OUTPUT_FILE = f'./RagOutputs/{DOC_ID}_{MODEL_ID}_{PARSER}_{CHUNK_SIZE}_{SPLITTER}_{TOP_K}.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import braintrust\n",
        "if use_braintrust_dataset:\n",
        "    dataset = braintrust.init_dataset(project=\"RagMetrics\", name=DOC_ID)\n",
        "    df = []\n",
        "    for row in dataset:\n",
        "        df.append(row)\n",
        "    # convert list of dict to pandas dataframe\n",
        "    dff = pd.DataFrame(df)\n",
        "    dff['question'] = dff['input'].apply(lambda x: x.split(\">\")[1])\n",
        "else:\n",
        "\n",
        "    df = pd.read_csv(COMPARISON_FILE)\n",
        "    if NUM_QUESTIONS == -1:\n",
        "        dff = df.copy()\n",
        "    else:\n",
        "        dff = df.head(NUM_QUESTIONS).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6gUzpLaeVpl5"
      },
      "outputs": [],
      "source": [
        "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"/Users/mbajaj/.env\")\n",
        "# API access to llama-cloud\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = os.getenv('LLAMA_CLOUD_API_KEY')\n",
        "# Using OpenAI API for embeddings/llms\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
        "os.environ[\"BRAINTRUST_API_KEY\"]=os.getenv('BRAINTRUST_API_KEY')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjWQnAYnVwhF",
        "outputId": "9907e56f-9e80-404e-b2d2-36f3ab269b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started parsing the file under job_id 95c39d88-adae-402b-ab10-cb466b01e63b\n"
          ]
        }
      ],
      "source": [
        "# from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "from llama_parse import LlamaParse\n",
        "if PARSER == \"llama-parse\":\n",
        "    documents = LlamaParse(result_type=\"markdown\").load_data(PDF_LOCATION)\n",
        "    len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "# generate unique index for multiple runs\n",
        "INDEX_NAME = ('X' + str(uuid.uuid4())).replace('-', '_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NfaNIvokpbKo"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "\n",
        "cluster_url = \"https://a0dlgmcaspopjrn2mtx4ha.c0.us-east1.gcp.weaviate.cloud\"\n",
        "api_key = \"7ZfUCibywHnzM0WKMPx7YevuN79nUtS4KJgT\"\n",
        "\n",
        "client = weaviate.connect_to_wcs(\n",
        "    cluster_url=cluster_url,\n",
        "    auth_credentials=weaviate.auth.AuthApiKey(api_key),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbN-rN7lsEy0"
      },
      "source": [
        "# weaviate vector database & llamaparse Integrated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# IBISWorld | Healthcare and Social Assistance in the US\n",
            "\n",
            "# Mar 2024\n",
            "\n",
            "- The dramatic rise in the adoption of telemedicine in 2020 has fallen from its pandemic high but is still more integral to healthcare delivery in 2024 than pre-COVID, especially for providers offering mental health treatment.\n",
            "- The challenges impacting healthcare providers are also expediting the adoption of other digital tools (AI, patient engagement products, data analytics) to streamline operations and produce cost savings.\n",
            "\n",
            "# Social assistance providers fill in the gaps as pandemic-era benefits end\n",
            "\n",
            "- The pandemic highlighted societal inequities. Social assistance providers have had an outsized role in addressing these inequities since the COVID-19 pandemic subsided.\n",
            "- Pandemic relief funding that cushioned savings accounts and lifted many out of poverty ended between 2022 and 2023, with exact end dates varying between states. As benefits disappeared, millions turned to social assistance providers for help with housing, food assistance and child care.\n",
            "- The end of pandemic food assistance benefits coupled with rising inflation have made affording the cost of essentials like groceries too expensive for many. Food banks nationwide have reported record need for their services, squeezing their staff and supplies thin.\n",
            "- Day Care (62441) providers are vital to addressing critical shortages of child care, especially as parents return to in-office work. The industry has struggled to recover from the pandemic as it attempts to meet excess demand, with the end of funding in late 2023 only exacerbating staffing issues, tight margins and steep fees.\n",
            "80\n"
          ]
        }
      ],
      "source": [
        "print(documents[20].text)\n",
        "print(len(documents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.schema import TextNode\n",
        "\n",
        "nodes = []\n",
        "if SPLITTER == \"sentence\":\n",
        "\n",
        "    splitter = SentenceSplitter(chunk_size=CHUNK_SIZE)\n",
        "    for idx, doc in enumerate(documents):\n",
        "        chunks = splitter.split_text(doc.text)\n",
        "        # create nodes with metadata\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            node = TextNode(text=chunk, metadata={'page_number': idx+1})\n",
        "            nodes.append(node)\n",
        "\n",
        "\n",
        "print(len(nodes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "hVThHH30qRoS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mbajaj/anaconda/envs/rag_omega/lib/python3.10/site-packages/weaviate/warnings.py:305: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
            "            Please make sure to close the connection using `client.close()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
        "\n",
        "vector_store = WeaviateVectorStore(\n",
        "    weaviate_client=client, index_name=INDEX_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "esw4x1faqmmS"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "vector_index = VectorStoreIndex(nodes, vector_store = vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "LMoIlj0qq-Wn"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=MODEL_ID, api_key = OPENAI_API_KEY)\n",
        "query_engine = vector_index.as_query_engine(similarity_top_k=TOP_K, llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((213, 7),\n",
              " './RagOutputs/ibis-healthcare-social-assistance_gpt-4o-mini_llama-parse_400_sentence_3.csv')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dff.shape, OUTPUT_FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = []\n",
        "references = []\n",
        "contexts = []\n",
        "for question in dff[QUESTION_COL]:\n",
        "    response = query_engine.query(question)\n",
        "    result.append((response.response))\n",
        "    metadata = response.metadata\n",
        "    refs = []\n",
        "    for m in metadata.values():\n",
        "        refs.append(m['page_number'])\n",
        "    references.append(refs)\n",
        "    q_contexts = []\n",
        "    for n in response.source_nodes:\n",
        "        q_contexts.append(n.text)\n",
        "    contexts.append(q_contexts)\n",
        "\n",
        "dff[RESPONSE_COL] = result\n",
        "dff['references'] = references\n",
        "dff['context'] = contexts\n",
        "dff.to_csv(OUTPUT_FILE, index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
